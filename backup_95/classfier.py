import torch
from transformers import ElectraForSequenceClassification, ElectraTokenizer, Trainer, TrainingArguments, TrainerCallback
import numpy as np
from torch.nn.functional import softmax
import pandas as pd
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset
import os
import pickle

# ê°ì • ë ˆì´ë¸” ì •ì˜ (7ê°€ì§€ ê°ì •)
emotion_labels = ["ê³µí¬", "ë†€ëŒ", "ë¶„ë…¸", "ìŠ¬í””", "ì¤‘ë¦½", "í–‰ë³µ", "í˜ì˜¤"]
label2id = {label: i for i, label in enumerate(emotion_labels)}

def load_koelectra_model(num_labels=7, use_saved=True, model_path="./finetuned_kcelectra"):
    from transformers import ElectraForSequenceClassification, ElectraConfig, BertTokenizer
    if use_saved and os.path.exists(model_path):
        model = ElectraForSequenceClassification.from_pretrained(model_path)
        tokenizer = BertTokenizer.from_pretrained(model_path)
        print(f"ëª¨ë¸ì„ {model_path}ì—ì„œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
    else:
        model_name = "beomi/KcELECTRA-base-v2022"
        tokenizer = BertTokenizer.from_pretrained(model_name)
        config = ElectraConfig.from_pretrained(model_name, num_labels=num_labels)
        model = ElectraForSequenceClassification.from_pretrained(model_name, config=config)
        print(f"ì‚¬ì „ í•™ìŠµëœ KoELECTRA ëª¨ë¸ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
    return model, tokenizer

def predict_emotion(text, model, tokenizer):
    """ì…ë ¥ëœ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤"""
    inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=128, padding=True)
    model.eval()
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
    probs = softmax(logits, dim=1).squeeze().numpy()
    predicted_class = np.argmax(probs)
    predicted_emotion = emotion_labels[predicted_class]
    confidence = probs[predicted_class]
    emotion_probs = {emotion: float(prob) for emotion, prob in zip(emotion_labels, probs)}
    return {
        "emotion": predicted_emotion,
        "confidence": float(confidence),
        "all_probabilities": emotion_probs
    }

class EmotionDataset(Dataset):
    def __init__(self, sentences, labels, tokenizer, max_len=128):
        self.sentences = sentences
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_len = max_len

    def __len__(self):
        return len(self.sentences)

    def __getitem__(self, idx):
        text = self.sentences[idx]
        label = self.labels[idx]
        encoding = self.tokenizer(
            text, truncation=True, padding='max_length', max_length=self.max_len, return_tensors='pt'
        )
        item = {key: val.squeeze(0) for key, val in encoding.items()}
        item['labels'] = torch.tensor(label)
        return item

class PrintProgressCallback(TrainerCallback):
    def on_epoch_begin(self, args, state, control, **kwargs):
        print(f"\n==== Epoch {int(state.epoch)+1} ì‹œì‘ ====")
    # def on_step_end(self, args, state, control, **kwargs):
    #     print(f"Step {state.global_step} / {state.max_steps} (Epoch {state.epoch:.2f})")
    def on_epoch_end(self, args, state, control, **kwargs):
        print(f"==== Epoch {int(state.epoch)+1} ì¢…ë£Œ ====")

def save_validation_data(val_df, save_path='validation_data.pkl'):
    """ê²€ì¦ ë°ì´í„°ì…‹ì„ ì €ì¥í•©ë‹ˆë‹¤"""
    with open(save_path, 'wb') as f:
        pickle.dump(val_df, f)
    print(f"ê²€ì¦ ë°ì´í„°ì…‹ì´ {save_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

def load_validation_data(load_path='validation_data.pkl'):
    """ì €ì¥ëœ ê²€ì¦ ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤"""
    try:
        with open(load_path, 'rb') as f:
            val_df = pickle.load(f)
        print(f"ê²€ì¦ ë°ì´í„°ì…‹ì„ {load_path}ì—ì„œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
        return val_df
    except FileNotFoundError:
        print(f"ì €ì¥ëœ ê²€ì¦ ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ê²€ì¦ ë°ì´í„°ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤.")
        return None

def finetune_and_save():
    # 1. ë°ì´í„° ë¡œë“œ
    file_path = r'c:/Users/nohyunwoo/Desktop/AI/data set/í•œêµ­ì–´ ê°ì • ì •ë³´ê°€ í¬í•¨ëœ ë‹¨ë°œì„± ëŒ€í™” ë°ì´í„°ì…‹/í•œêµ­ì–´_ë‹¨ë°œì„±_ëŒ€í™”_ë°ì´í„°ì…‹.xlsx'
    df = pd.read_excel(file_path)
    
    # ìœ ì‚¬í•œ ê°ì • ìŒ ì •ì˜
    similar_emotion_pairs = [
        # ğŸ’¥ ê°•í•œ ìƒí˜¸ í˜¼ë™ (í˜¼ë™ ìˆ˜ì¹˜ ë§¤ìš° ë†’ìŒ)
        ('ë¶„ë…¸', 'í˜ì˜¤'),
        ('í˜ì˜¤', 'ë¶„ë…¸'),
        ('ë¶„ë…¸', 'ì¤‘ë¦½'),
        ('ì¤‘ë¦½', 'ë¶„ë…¸'),
        ('ê³µí¬', 'ë†€ëŒ'),
        ('ë†€ëŒ', 'ê³µí¬'),
        ('ì¤‘ë¦½', 'ë†€ëŒ'),
        ('ë†€ëŒ', 'ì¤‘ë¦½'),
        ('ì¤‘ë¦½', 'í˜ì˜¤'),
        ('í˜ì˜¤', 'ì¤‘ë¦½'),
        ('í–‰ë³µ', 'ì¤‘ë¦½'),
        ('ì¤‘ë¦½', 'í–‰ë³µ'),
        ('í–‰ë³µ', 'ë†€ëŒ'),
        ('ë†€ëŒ', 'í–‰ë³µ'),
        ('ìŠ¬í””', 'ê³µí¬'),
        ('ê³µí¬', 'ìŠ¬í””'),
        ('ìŠ¬í””', 'í˜ì˜¤'),
        ('í˜ì˜¤', 'ìŠ¬í””'),
             
    ]
    # pair_oversample_factor ë”•ì…”ë„ˆë¦¬ ì‚­ì œë¨

    # ìœ ì‚¬í•œ ê°ì • ìŒì˜ ë°ì´í„° ì¦ê°• (ë³µì œ ê°•ë„ ì ìš©)
    augmented_data = []
    for pair in similar_emotion_pairs:
        emotion1, emotion2 = pair
        data1 = df[df['Emotion'] == emotion1]
        data2 = df[df['Emotion'] == emotion2]
        min_size = min(len(data1), len(data2))
        factor = 1  # ê¸°ë³¸ê°’ 1
        if len(data1) < len(data2):
            data1 = data1.sample(n=min_size * factor, replace=True)
            data2 = data2.sample(n=min_size * factor, replace=True)
        else:
            data1 = data1.sample(n=min_size * factor, replace=True)
            data2 = data2.sample(n=min_size * factor, replace=True)
        augmented_data.extend([data1, data2])
    if augmented_data:
        df = pd.concat([df] + augmented_data, ignore_index=True)
    
    # ì „ì²´ ë°ì´í„°ì…‹ì˜ ë ˆì´ë¸” ë¶„í¬ í™•ì¸
    print("\n=== ì „ì²´ ë°ì´í„°ì…‹ ë ˆì´ë¸” ë¶„í¬ ===")
    print(df['Emotion'].value_counts())
    print("\në ˆì´ë¸” ìˆœì„œ:", emotion_labels)
    
    # ìœ íš¨í•œ ë ˆì´ë¸”ë§Œ í•„í„°ë§
    df = df[df['Emotion'].isin(label2id)]
    print("\n=== í•„í„°ë§ í›„ ë ˆì´ë¸” ë¶„í¬ ===")
    print(df['Emotion'].value_counts())
    
    # 2. ë°ì´í„°ë¥¼ í•™ìŠµ(60%), ê²€ì¦(20%), í…ŒìŠ¤íŠ¸(20%)ë¡œ ë¶„í• 
    # ë¨¼ì € í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë¶„ë¦¬
    train_val_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['Emotion'])
    # ë‚˜ë¨¸ì§€ ë°ì´í„°ì—ì„œ í•™ìŠµê³¼ ê²€ì¦ ì„¸íŠ¸ ë¶„ë¦¬
    train_df, val_df = train_test_split(train_val_df, test_size=0.25, random_state=42, stratify=train_val_df['Emotion'])
    # (0.8 * 0.25 = 0.2ì´ë¯€ë¡œ, ì „ì²´ì˜ 20%ê°€ ê²€ì¦ ì„¸íŠ¸)
    
    # ê° ë°ì´í„°ì…‹ì˜ í¬ê¸°ì™€ ë ˆì´ë¸” ë¶„í¬ ì¶œë ¥
    print("\n=== ë°ì´í„°ì…‹ ë¶„í•  ê²°ê³¼ ===")
    print(f"í•™ìŠµ ë°ì´í„° í¬ê¸°: {len(train_df)} ìƒ˜í”Œ")
    print("\ní•™ìŠµ ë°ì´í„° ë ˆì´ë¸” ë¶„í¬:")
    print(train_df['Emotion'].value_counts())
    
    print(f"\nê²€ì¦ ë°ì´í„° í¬ê¸°: {len(val_df)} ìƒ˜í”Œ")
    print("\nê²€ì¦ ë°ì´í„° ë ˆì´ë¸” ë¶„í¬:")
    print(val_df['Emotion'].value_counts())
    
    print(f"\ní…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: {len(test_df)} ìƒ˜í”Œ")
    print("\ní…ŒìŠ¤íŠ¸ ë°ì´í„° ë ˆì´ë¸” ë¶„í¬:")
    print(test_df['Emotion'].value_counts())
    
    manual_weights = {
        'ê³µí¬': 1.4,    # ìŠ¬í””/ë†€ëŒ í˜¼ë™ ë³´ì •
        'ë†€ëŒ': 1.2,    # ì„±ëŠ¥ ë†’ê³  ì‹ ë¢°ë„ ë†’ìŒ
        'ë¶„ë…¸': 1.6,    # í˜ì˜¤ì™€ ëŒ€í˜¼ë™ ë³´ì •
        'ìŠ¬í””': 1.5,    # recall/precision ë‚®ìŒ
        'ì¤‘ë¦½': 1.2,    # ë†€ëŒ/í˜ì˜¤ í˜¼ë™ ë³´ì •
        'í–‰ë³µ': 1.4,    # ìŠ¬í””ê³¼ í˜¼ë™
        'í˜ì˜¤': 1.6     # ë¶„ë…¸ì™€ì˜ í˜¼ë™
    }

    confusion_penalty = {
        'ê³µí¬': 1.25,   # ìŠ¬í”” í˜¼ë™ ê°•í•¨
        'ë†€ëŒ': 1.1,    # ì„±ëŠ¥ ì•ˆì •ì 
        'ë¶„ë…¸': 1.57,    # í˜ì˜¤ í˜¼ë™ í¼
        'ìŠ¬í””': 1.3,    # recall ë‚®ê³  ì˜¤ë¶„ë¥˜ í¼
        'ì¤‘ë¦½': 1.2,    # ë‹¤ë°©ë©´ í˜¼ë™
        'í–‰ë³µ': 1.3,    # ìŠ¬í””/ì¤‘ë¦½ê³¼ ì„ì„
        'í˜ì˜¤': 1.4    # ë¶„ë…¸/ì¤‘ë¦½ê³¼ í˜¼ë™
    }

    # 3. ìµœì¢… ê°€ì¤‘ì¹˜
    final_weights = {
        label: manual_weights[label] * confusion_penalty[label]
        for label in emotion_labels
    }
    weights = torch.tensor([final_weights[label] for label in emotion_labels])

    print("\n=== ìµœì¢… í´ë˜ìŠ¤ë³„ ê°€ì¤‘ì¹˜ ===")
    for label in emotion_labels:
        print(f"{label}: {final_weights[label]:.2f}")
    
    # 3. í•™ìŠµ/ê²€ì¦ìš© ë°ì´í„°ì…‹ ì¤€ë¹„
    train_texts = train_df['Sentence'].tolist()
    train_labels = train_df['Emotion'].map(label2id).tolist()
    val_texts = val_df['Sentence'].tolist()
    val_labels = val_df['Emotion'].map(label2id).tolist()
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” ë³„ë„ë¡œ ì €ì¥ (ë‚˜ì¤‘ì— í‰ê°€ìš©)
    test_df.to_csv('./test_data.csv', index=False)
    print("\ní…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ 'test_data.csv'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # 4. í† í¬ë‚˜ì´ì € ë° ë°ì´í„°ì…‹ ìƒì„±
    from transformers import BertTokenizer
    tokenizer = BertTokenizer.from_pretrained("beomi/KcELECTRA-base-v2022")
    train_dataset = EmotionDataset(train_texts, train_labels, tokenizer)
    val_dataset = EmotionDataset(val_texts, val_labels, tokenizer)
    
    # 5. ëª¨ë¸ ì¤€ë¹„
    from transformers import ElectraForSequenceClassification
    model = ElectraForSequenceClassification.from_pretrained(
        "beomi/KcELECTRA-base-v2022",
        num_labels=7,
        hidden_dropout_prob=0.2,  # ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨ ì¦ê°€
        attention_probs_dropout_prob=0.2
    )
    
    # ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ ì†ì‹¤ í•¨ìˆ˜ ì •ì˜
    class WeightedLossTrainer(Trainer):
        def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):
            labels = inputs.pop("labels")
            outputs = model(**inputs)
            logits = outputs.logits
            
            # ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ CrossEntropyLoss
            loss_fct = torch.nn.CrossEntropyLoss(weight=weights.to(model.device))
            loss = loss_fct(logits, labels)
            
            return (loss, outputs) if return_outputs else loss
    
    # 6. Trainerë¡œ íŒŒì¸íŠœë‹
    training_args = TrainingArguments(
        output_dir='./results',
        num_train_epochs=5,               # ì—í­ ìˆ˜
        per_device_train_batch_size=8,     # ë°°ì¹˜ í¬ê¸°
        per_device_eval_batch_size=8,      # í‰ê°€ ë°°ì¹˜ í¬ê¸°
        gradient_accumulation_steps=2,  # ì‹¤ì§ˆì  ë°°ì¹˜ 32
        weight_decay=0.01,
        logging_dir='./logs',
        logging_steps=100,                  # ë¡œê¹… ìŠ¤í…
        eval_strategy="steps",
        eval_steps=500,
        save_strategy="steps",
        save_steps=500,
        save_total_limit=3,                # ìµœëŒ€ 3ê°œì˜ ì²´í¬í¬ì¸íŠ¸ë§Œ ì €ì¥
        load_best_model_at_end=True,
        metric_for_best_model="macro_f1",
        report_to="none",
        learning_rate=2e-5,               # í•™ìŠµë¥ 
        warmup_steps=660,                   # ì›Œë°ì—… ìŠ¤í…
        lr_scheduler_type='cosine_with_restarts',
        fp16=True,
        save_safetensors=True,            # ì•ˆì „í•œ í˜•ì‹ìœ¼ë¡œ ì €ì¥
    )
    
    def compute_metrics(eval_pred):
        logits, labels = eval_pred
        predictions = np.argmax(logits, axis=-1)
        
        # ê° í´ë˜ìŠ¤ë³„ ì˜ˆì¸¡ ìˆ˜ ê³„ì‚°
        pred_counts = np.bincount(predictions, minlength=len(emotion_labels))
        true_counts = np.bincount(labels, minlength=len(emotion_labels))
        
        # ì •í™•ë„ ê³„ì‚°
        accuracy = np.mean(predictions == labels)
        
        # Macro F1 ìŠ¤ì½”ì–´ ê³„ì‚° ì¶”ê°€
        from sklearn.metrics import f1_score
        macro_f1 = f1_score(labels, predictions, average='macro')
        
        # Label Smoothingì´ ì ìš©ëœ ì†ì‹¤ê°’ ê³„ì‚°
        smoothing = 0.1  # Label Smoothing ê³„ìˆ˜
        num_classes = len(emotion_labels)
        
        # ì›-í•« ì¸ì½”ë”©ìœ¼ë¡œ ë³€í™˜
        labels_one_hot = torch.zeros(len(labels), num_classes)
        labels_one_hot.scatter_(1, torch.tensor(labels).unsqueeze(1), 1)
        
        # Label Smoothing ì ìš©
        labels_one_hot = labels_one_hot * (1 - smoothing) + smoothing / num_classes
        
        # CrossEntropyLoss ê³„ì‚°
        loss_fct = torch.nn.CrossEntropyLoss()
        loss = loss_fct(torch.tensor(logits), labels_one_hot)
        
        # ê° í´ë˜ìŠ¤ë³„ ì •í™•ë„ ê³„ì‚°
        class_accuracies = {}
        for i in range(len(emotion_labels)):
            mask = labels == i
            if np.sum(mask) > 0:  # í•´ë‹¹ í´ë˜ìŠ¤ì˜ ìƒ˜í”Œì´ ìˆëŠ” ê²½ìš°
                class_acc = np.mean(predictions[mask] == labels[mask])
                class_accuracies[f"{emotion_labels[i]}_accuracy"] = class_acc
        
        return {
            "accuracy": accuracy,
            "macro_f1": macro_f1,  # macro_f1 ì¶”ê°€
            "loss": loss.item(),
            "class_distribution": {emotion: count for emotion, count in zip(emotion_labels, pred_counts)},
            "true_distribution": {emotion: count for emotion, count in zip(emotion_labels, true_counts)},
            **class_accuracies
        }
    
    # Early Stopping ì½œë°± ì¶”ê°€
    from transformers import EarlyStoppingCallback
    early_stopping = EarlyStoppingCallback(
        early_stopping_patience=3,        # 3ë²ˆì˜ í‰ê°€ì—ì„œ ê°œì„ ì´ ì—†ìœ¼ë©´ ì¤‘ë‹¨
        early_stopping_threshold=0.001    # ìµœì†Œ ê°œì„  ê¸°ì¤€
    )
    
    # ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ Trainer ì‚¬ìš©
    trainer = WeightedLossTrainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        compute_metrics=compute_metrics,
        callbacks=[PrintProgressCallback(), early_stopping],
    )
    

    print("ì²˜ìŒë¶€í„° í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    trainer.train()
    
    # 7. ëª¨ë¸ ì €ì¥
    model.save_pretrained('./finetuned_kcelectra')
    tokenizer.save_pretrained('./finetuned_kcelectra')
    print("ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ê°€ './finetuned_kcelectra'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

def evaluate_on_test_data():
    """ì €ì¥ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤"""
    print("ì €ì¥ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤...")
    
    # ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
    model, tokenizer = load_koelectra_model(use_saved=True)
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
    test_df = pd.read_csv('./test_data.csv')
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ê°ì • ë¶„í¬ ì¶œë ¥
    print("\ní…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ê°ì • ë¶„í¬:")
    print(test_df['Emotion'].value_counts())
    
    # ì˜ˆì¸¡ ë° í‰ê°€
    true_labels = test_df['Emotion'].map(label2id).tolist()
    pred_labels = []
    all_probs = []
    
    print("\nê° ë¬¸ì¥ë³„ ì˜ˆì¸¡ ê²°ê³¼:")
    for idx, sentence in enumerate(test_df['Sentence'].tolist()):
        result = predict_emotion(sentence, model, tokenizer)
        pred_emotion = result['emotion']
        pred_labels.append(label2id[pred_emotion])
        all_probs.append(result['all_probabilities'])
        
        # ì²˜ìŒ 5ê°œ ë¬¸ì¥ë§Œ ìƒì„¸ ì¶œë ¥
        if idx < 5:
            print(f"\në¬¸ì¥ {idx+1}: {sentence}")
            print(f"ì‹¤ì œ ê°ì •: {test_df['Emotion'].iloc[idx]}")
            print(f"ì˜ˆì¸¡ ê°ì •: {pred_emotion} (ì‹ ë¢°ë„: {result['confidence']:.4f})")
            print("ëª¨ë“  ê°ì • í™•ë¥ :")
            for emotion, prob in sorted(result['all_probabilities'].items(), key=lambda x: x[1], reverse=True):
                print(f"  - {emotion}: {prob:.4f}")
    
    # í‰ê°€ ì§€í‘œ ê³„ì‚°
    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
    
    accuracy = accuracy_score(true_labels, pred_labels)
    report = classification_report(true_labels, pred_labels, target_names=emotion_labels)
    conf_matrix = confusion_matrix(true_labels, pred_labels)
    
    print(f"\n=== ì „ì²´ í‰ê°€ ê²°ê³¼ ===")
    print(f"í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì •í™•ë„: {accuracy:.4f}")
    print("\në¶„ë¥˜ ë¦¬í¬íŠ¸:")
    print(report)
    
    print("\ní˜¼ë™ í–‰ë ¬:")
    print(conf_matrix)
    
    # ê° ê°ì •ë³„ í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
    print("\n=== ê° ê°ì •ë³„ í‰ê·  ì‹ ë¢°ë„ ===")
    for emotion in emotion_labels:
        emotion_idx = label2id[emotion]
        emotion_probs = [probs[emotion] for probs in all_probs]
        avg_confidence = sum(emotion_probs) / len(emotion_probs)
        print(f"{emotion}: {avg_confidence:.4f}")

def main():
    print("KoELECTRA ê°ì • ë¶„ì„ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

    # ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
    try:
        model, tokenizer = load_koelectra_model(use_saved=True)
        print("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
    except Exception as e:
        print(f"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return

    # í…ŒìŠ¤íŠ¸í•  ë¬¸ì¥ë“¤
    test_sentences = [
        "ì˜¤ëŠ˜ì€ ë‚ ì”¨ê°€ ë„ˆë¬´ ì¢‹ì•„ì„œ ê¸°ë¶„ì´ ì¢‹ì•„ìš”!",
        "ì‹œí—˜ì—ì„œ ë–¨ì–´ì ¸ì„œ ë„ˆë¬´ ìŠ¬í¼ìš”.",
        "ì´ ìƒí™©ì´ ë„ˆë¬´ í™”ê°€ ë‚˜ê³  ì§œì¦ì´ ë‚©ë‹ˆë‹¤.",
        "ê°‘ìê¸° ë¬´ì„œìš´ ì†Œë¦¬ê°€ ë“¤ë ¤ì„œ ì‹¬ì¥ì´ ì¿µì¾…ê±°ë ¤ìš”.",
        "ì´ ìŒì‹ì€ ë„ˆë¬´ ì´ìƒí•œ ëƒ„ìƒˆê°€ ë‚˜ì„œ ë¨¹ì„ ìˆ˜ ì—†ì„ ê²ƒ ê°™ì•„ìš”.",
        "ê°‘ìê¸° ì¹œêµ¬ê°€ ë’¤ì—ì„œ ë†€ë˜ì¼œì„œ ê¹œì§ ë†€ëì–´ìš”.",
        "ì˜¤ëŠ˜ ë‚ ì”¨ëŠ” ë§‘ê³  ê¸°ì˜¨ì€ 23ë„ì…ë‹ˆë‹¤."
    ]

    # ê° ë¬¸ì¥ì— ëŒ€í•œ ê°ì • ì˜ˆì¸¡
    print("\n=== ê°ì • ë¶„ì„ ê²°ê³¼ ===")
    for i, sentence in enumerate(test_sentences):
        result = predict_emotion(sentence, model, tokenizer)
        print(f"\n[ë¬¸ì¥ {i+1}] {sentence}")
        print(f"ì˜ˆì¸¡ ê°ì •: {result['emotion']} (ì‹ ë¢°ë„: {result['confidence']:.4f})")
        print("ëª¨ë“  ê°ì • í™•ë¥ :")
        sorted_probs = sorted(result['all_probabilities'].items(), key=lambda x: x[1], reverse=True)
        for emotion, prob in sorted_probs:
            print(f"  - {emotion}: {prob:.4f}")

def evaluate_model():
    """ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤"""
    print("KoELECTRA ê°ì • ë¶„ì„ ëª¨ë¸ í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    # ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
    model, tokenizer = load_koelectra_model(use_saved=True)
    
    # ì €ì¥ëœ ê²€ì¦ ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°
    test_df = load_validation_data()
    
    # ì €ì¥ëœ ê²€ì¦ ë°ì´í„°ì…‹ì´ ì—†ëŠ” ê²½ìš° ìƒˆë¡œìš´ ë°ì´í„°ì…‹ ìƒì„±
    if test_df is None:
        file_path = r'c:/Users/nohyunwoo/Desktop/AI/data set/í•œêµ­ì–´ ê°ì • ì •ë³´ê°€ í¬í•¨ëœ ë‹¨ë°œì„± ëŒ€í™” ë°ì´í„°ì…‹/í•œêµ­ì–´_ë‹¨ë°œì„±_ëŒ€í™”_ë°ì´í„°ì…‹.xlsx'
        df = pd.read_excel(file_path)
        df = df[df['Emotion'].isin(label2id)]
        _, test_df = train_test_split(df, test_size=0.2, random_state=42)
        save_validation_data(test_df)
    
    # ì‹¤ì œ ë ˆì´ë¸”ê³¼ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    true_labels = []
    pred_labels = []
    
    # ê° ë¬¸ì¥ì— ëŒ€í•œ ê°ì • ì˜ˆì¸¡
    print("\nê²€ì¦ ë°ì´í„°ì…‹ í‰ê°€ ì¤‘...")
    for idx, row in test_df.iterrows():
        sentence = row['Sentence']
        true_emotion = row['Emotion']
        true_label = label2id[true_emotion]
        
        result = predict_emotion(sentence, model, tokenizer)
        pred_emotion = result['emotion']
        pred_label = label2id[pred_emotion]
        
        true_labels.append(true_label)
        pred_labels.append(pred_label)
        
    # í‰ê°€ ì§€í‘œ ê³„ì‚°
    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
    
    accuracy = accuracy_score(true_labels, pred_labels)
    report = classification_report(true_labels, pred_labels, target_names=emotion_labels)
    conf_matrix = confusion_matrix(true_labels, pred_labels)
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\n=== ëª¨ë¸ í‰ê°€ ê²°ê³¼ ===")
    print(f"ì •í™•ë„ (Accuracy): {accuracy:.4f}")
    print("\në¶„ë¥˜ ë¦¬í¬íŠ¸:")
    print(report)
    
    print("\ní˜¼ë™ í–‰ë ¬ (Confusion Matrix):")
    print(conf_matrix)
    
    # ê²°ê³¼ë¥¼ ì‹œê°í™”
    try:
        import matplotlib.pyplot as plt
        import seaborn as sns
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
                    xticklabels=emotion_labels, yticklabels=emotion_labels)
        plt.xlabel('ì˜ˆì¸¡ëœ ê°ì •')
        plt.ylabel('ì‹¤ì œ ê°ì •')
        plt.title('ê°ì • ë¶„ë¥˜ í˜¼ë™ í–‰ë ¬')
        plt.tight_layout()
        plt.savefig('confusion_matrix.png')
        print("\ní˜¼ë™ í–‰ë ¬ ì´ë¯¸ì§€ê°€ 'confusion_matrix.png' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except ImportError:
        print("\nì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ê·¸ë˜í”„ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # ì˜¤ë¶„ë¥˜ëœ ì˜ˆì‹œ í™•ì¸
    print("\n=== ì˜¤ë¶„ë¥˜ëœ ì˜ˆì‹œ ===")
    misclassified = []
    for idx, row in test_df.iterrows():
        sentence = row['Sentence']
        true_emotion = row['Emotion']
        
        result = predict_emotion(sentence, model, tokenizer)
        pred_emotion = result['emotion']
        
        if true_emotion != pred_emotion:
            misclassified.append({
                'sentence': sentence,
                'true_emotion': true_emotion,
                'predicted_emotion': pred_emotion,
                'confidence': result['confidence']
            })
    
    # ì˜¤ë¶„ë¥˜ëœ ì˜ˆì‹œ ì¤‘ ì¼ë¶€ ì¶œë ¥
    sample_size = min(10, len(misclassified))
    for i, example in enumerate(misclassified[:sample_size]):
        print(f"\n[ì˜¤ë¶„ë¥˜ ì˜ˆì‹œ {i+1}]")
        print(f"ë¬¸ì¥: {example['sentence']}")
        print(f"ì‹¤ì œ ê°ì •: {example['true_emotion']}")
        print(f"ì˜ˆì¸¡ ê°ì •: {example['predicted_emotion']} (ì‹ ë¢°ë„: {example['confidence']:.4f})")

def check_model_output():
    model, tokenizer = load_koelectra_model(use_saved=True)
    test_text = "ì˜¤ëŠ˜ì€ ì •ë§ í™”ê°€ ë‚©ë‹ˆë‹¤."
    inputs = tokenizer(test_text, return_tensors="pt")
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        probs = softmax(logits, dim=1).squeeze().numpy()
    print("ëª¨ë¸ ì¶œë ¥ í™•ë¥ :", probs)
    print("ì˜ˆì¸¡ëœ í´ë˜ìŠ¤:", np.argmax(probs))
    print("ì˜ˆì¸¡ëœ ê°ì •:", emotion_labels[np.argmax(probs)])

def interactive_inference():
    print("\n=== KoELECTRA ê°ì • ì‹¤ì‹œê°„ ì˜ˆì¸¡ ===")
    model, tokenizer = load_koelectra_model(use_saved=True, model_path="./finetuned_kcelectra")
    while True:
        text = input("\në¬¸ì¥ ì…ë ¥ (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥): ")
        if text.strip().lower() == 'exit':
            print("ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        result = predict_emotion(text, model, tokenizer)
        print(f"\nì˜ˆì¸¡ ê°ì •: {result['emotion']} (ì‹ ë¢°ë„: {result['confidence']:.4f})")
        print("ëª¨ë“  ê°ì • í™•ë¥ :")
        for emotion, prob in sorted(result['all_probabilities'].items(), key=lambda x: x[1], reverse=True):
            print(f"  - {emotion}: {prob:.4f}")

if __name__ == "__main__":
    # ëª¨ë¸ ì¶œë ¥ í™•ì¸
    # check_model_output()
    
    # íŒŒì¸íŠœë‹ ë° ì €ì¥ì„ ì›í•  ë•Œ ì•„ë˜ í•¨ìˆ˜ ì‹¤í–‰
    # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì´ì–´ì„œ í•™ìŠµí•˜ë ¤ë©´ True, ì²˜ìŒë¶€í„° í•™ìŠµí•˜ë ¤ë©´ False
    # finetune_and_save()  # ì²˜ìŒë¶€í„° í•™ìŠµ
    
    # ê°ì • ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ë¥¼ ì›í•  ë•Œ main() ì‹¤í–‰
    # main()
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ëª¨ë¸ í‰ê°€ë¥¼ ì›í•  ë•Œ evaluate_on_test_data() ì‹¤í–‰
    # evaluate_on_test_data()
    
    # ì‹¤ì‹œê°„ ê°ì • ì˜ˆì¸¡ ì‹¤í–‰
    interactive_inference()